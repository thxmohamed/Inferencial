---
title: "Lectura 13"
author: "Benjamín Bustamante y Mohamed Al-Marzuk"
date: "`r Sys.Date()`"
output: html_document
---

REGRESIÓN LINEAL SIMPLE (RLS)

Se usa cuando los datos tienen una tendencia lineal. Si presentan una tendencia no lineal, hay que usar otras herramientas más avanzadas.

Hay ciertas condiciones que deben cumplirse antes de aplicar RL mediante mínimos cuadrados:

1) LAs variables presentan una distribución condicional bivariante, por lo que, para cualquier valor fijo de X, los valores de Y se distribuyen normalmente con una varianza constante.

2) La relación entre la variable X y las medias de la variable Y es lineal.

3) Las observaciones de la muestra son independientes entre sí. Esto significa que no se puede usar regresión lineal con series de tiempo (qué).

Ajuste de una regresión lineal simple

```{r}

library(dplyr)
library(ggpubr)

# Cargar y filtrar los datos
datos <- mtcars |> filter(wt > 2 & wt < 5)

# Ajustar modelo con R
modelo <- lm(hp ~ disp, data = datos)
print(summary(modelo))
```
Ahora, graficamos

```{r}
g1 <- ggscatter(datos, x = "disp", y = "hp",
                color = "steelblue", fill = "steelblue",
                ylab = "Potencia [hp]")
g1 <- g1 + geom_abline(intercept = coef(modelo)[1],
                       slope = coef(modelo)[2],
                       color = "red")
g1 <- g1 + xlab(bquote("Volumen útil de los cilindros" ~ 
                       "[" * "in"^3 * "]"))

plot(g1)
```

Definir los valores del predictor para vehículos no incluidos en el conjunto mtcars
```{r}
disp <- c(169.694, 230.214, 79.005, 94.085, 343.085,
          136.073, 357.305, 288.842, 223.128, 129.217,
          126.432, 193.474, 376.874, 202.566, 114.928)

# Usar el modelo para predecir el rendimiento de estos modelos.
potencia_est <- predict(modelo, data.frame(disp))

# Graficar los valores predichos
nuevos <- data.frame(disp, hp = potencia_est)
g2 <- ggscatter(nuevos, x = "disp", y = "hp",
                color = "purple", fill = "purple",
                ylab = "Potencia [hp]")
g2 <- g2 + xlab(bquote("Volumen útil de los cilindros" ~ "[" * "in"^3 * "]"))

# Unir los gráficos en uno solo
g1 <- ggpar(g1, xlim = c(75, 405), ylim = c(60, 340))
g2 <- ggpar(g2, xlim = c(75, 405), ylim = c(60, 340))
g <- ggarrange(g1, g2,
               labels = c("Modelo", "Predicciones"),
               hjust = c(-1.2, -0.7))
print(g)
```

Regresión lineal con un predictor categórico

Solo se va a estudiar el caso de una variable dicotómica. Para eso se crea una nueva variable indicadora que toma los valores 0 y 1. Se hace automáticamente en R nomas.

```{r}
library(ggpubr)

datos <- mtcars |> filter(wt > 2 & wt < 5)

# Verificar correlación
print(cor(datos[, c("hp", "am", "vs")]))

# Ajustar modelo con R
modelo_vs <- lm(hp ~ vs, data = datos)
print(summary(modelo_vs))

```
Graficamos
```{r}
g1 <- ggscatter(datos, x = "vs", y = "hp",
                color = "steelblue", fill = "steelblue",
                xlab = "Forma del motor", ylab = "Potencia [hp]",
                xticks.by = 1)

g1 <- g1 + geom_abline(intercept = coef(modelo_vs)[1],
                      slope = coef(modelo_vs)[2],
                      color = "red")

print(g1)

```
Graficamos los residuos

```{r}
residuos <- modelo_vs[["residuals"]]
datos <- cbind(datos, residuos)

g2 <- ggscatter(datos, x = "vs", y = "residuos",
                color = "steelblue", fill = "steelblue",
                xlab = "Forma del motor", ylav = "Residuos [hp]",
                xticks.by = 1)

g2 <- g2 + geom_hline(yintercept = 0, color = "red")

# Unir gráficos

g <- ggarrange(g1, g2, labels = c("Modelo", "Residuos"),
               hjust = c(-2.5, -2.0))

print(g)

```
CONFIABILIDAD DE UN MODELO DE RLS

Es difícil comprobar las condiciones de los mínimos cuadrados. Hay que realizar esas verificaciones antes, puesto que si se está violando alguna condición o no se ajusta a los datos, no es posible confiar en las predicciones entregadas.

1) Bondad de ajuste: es el R cuadrado, sale en lm()

2) Distribución e independencia: cuando se cumplen las condiciones de los mínimos cuadrados, se observan ciertas características en el gráfico de los residuos:

- Se distribuyen aleatoriamente en torno a la línea de valor cero

- Forman una banda horizontal en torno a la línea de valor cero

- no hay residuos que se alejen del patrón que forman los demás

- no forman un patrón reconocible

Si se observan las características 1 y 4 es razonable suponer que las variables presentan una relación lineal.

el paquete car ofrece funciones para realizar el diagnóstico de modelos de regresión, entre ellos, está residualPlots(modelo, type = "pearson") que despliega gráficos de residuos.

También está marginalModelProts(modelo, sd = FALSE)

Evaluación del modelo

```{r}
library(car)
library(dplyr)
library(ggpubr)

# Cargar y filtrar los datos

datos <- mtcars |> filter(wt > 2 & wt < 5)

# Ajustar modelo con R

modelo <- lm(hp ~ disp, data = datos)

# Desplegar gráficos de residuos y mostrar pruebas de curvatura

cat("Pruebas de curvatura:\n")

residualPlots(modelo, type = "rstandard",
              id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
              col = "steelblue", pch = 20, col.quad = "red")

```

Verificar independencia de los residuos
```{r}
set.seed(19)
db <- durbinWatsonTest(modelo)
cat("\nPrueba de independencia:\n")
print(db)
```

Desplegar gráficos marginales
```{r}
marginalModelPlots(modelo, sd = TRUE,
                   id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
                   col = "steelblue", pch = 20, col.line = c("steelblue", "red"))
```

Prueba de la varianza del error no constante

```{r}
cat("\nPrueba de homocedasticidad:\n")
print(ncvTest(modelo))
```

Desplegar gráficos de influencia
```{r}
casos_influyentes <- influencePlot(modelo, id = list(cex = 0.7))
cat("\nCasos que podrían ser influyentes:\n")
print(casos_influyentes)
```


Calidad predictiva de un modelo de RLS.

Un modelo será generali











