---
title: "Lectura 13"
author: "Benjamín Bustamante y Mohamed Al-Marzuk"
date: "`r Sys.Date()`"
output: html_document
---

REGRESIÓN LINEAL SIMPLE (RLS)

Se usa cuando los datos tienen una tendencia lineal. Si presentan una tendencia no lineal, hay que usar otras herramientas más avanzadas.

Hay ciertas condiciones que deben cumplirse antes de aplicar RL mediante mínimos cuadrados:

1) LAs variables presentan una distribución condicional bivariante, por lo que, para cualquier valor fijo de X, los valores de Y se distribuyen normalmente con una varianza constante.

2) La relación entre la variable X y las medias de la variable Y es lineal.

3) Las observaciones de la muestra son independientes entre sí. Esto significa que no se puede usar regresión lineal con series de tiempo (qué).

Ajuste de una regresión lineal simple

```{r}

library(dplyr)
library(ggpubr)

# Cargar y filtrar los datos
datos <- mtcars |> filter(wt > 2 & wt < 5)

# Ajustar modelo con R
modelo <- lm(hp ~ disp, data = datos)
print(summary(modelo))
```
Ahora, graficamos

```{r}
g1 <- ggscatter(datos, x = "disp", y = "hp",
                color = "steelblue", fill = "steelblue",
                ylab = "Potencia [hp]")
g1 <- g1 + geom_abline(intercept = coef(modelo)[1],
                       slope = coef(modelo)[2],
                       color = "red")
g1 <- g1 + xlab(bquote("Volumen útil de los cilindros" ~ 
                       "[" * "in"^3 * "]"))

plot(g1)
```

Definir los valores del predictor para vehículos no incluidos en el conjunto mtcars
```{r}
disp <- c(169.694, 230.214, 79.005, 94.085, 343.085,
          136.073, 357.305, 288.842, 223.128, 129.217,
          126.432, 193.474, 376.874, 202.566, 114.928)

# Usar el modelo para predecir el rendimiento de estos modelos.
potencia_est <- predict(modelo, data.frame(disp))

# Graficar los valores predichos
nuevos <- data.frame(disp, hp = potencia_est)
g2 <- ggscatter(nuevos, x = "disp", y = "hp",
                color = "purple", fill = "purple",
                ylab = "Potencia [hp]")
g2 <- g2 + xlab(bquote("Volumen útil de los cilindros" ~ "[" * "in"^3 * "]"))

# Unir los gráficos en uno solo
g1 <- ggpar(g1, xlim = c(75, 405), ylim = c(60, 340))
g2 <- ggpar(g2, xlim = c(75, 405), ylim = c(60, 340))
g <- ggarrange(g1, g2,
               labels = c("Modelo", "Predicciones"),
               hjust = c(-1.2, -0.7))
print(g)
```

Regresión lineal con un predictor categórico

Solo se va a estudiar el caso de una variable dicotómica. Para eso se crea una nueva variable indicadora que toma los valores 0 y 1. Se hace automáticamente en R nomas.

```{r}
library(ggpubr)

datos <- mtcars |> filter(wt > 2 & wt < 5)

# Verificar correlación
print(cor(datos[, c("hp", "am", "vs")]))

# Ajustar modelo con R
modelo_vs <- lm(hp ~ vs, data = datos)
print(summary(modelo_vs))

```
Graficamos
```{r}
g1 <- ggscatter(datos, x = "vs", y = "hp",
                color = "steelblue", fill = "steelblue",
                xlab = "Forma del motor", ylab = "Potencia [hp]",
                xticks.by = 1)

g1 <- g1 + geom_abline(intercept = coef(modelo_vs)[1],
                      slope = coef(modelo_vs)[2],
                      color = "red")

print(g1)

```
Graficamos los residuos

```{r}
residuos <- modelo_vs[["residuals"]]
datos <- cbind(datos, residuos)

g2 <- ggscatter(datos, x = "vs", y = "residuos",
                color = "steelblue", fill = "steelblue",
                xlab = "Forma del motor", ylav = "Residuos [hp]",
                xticks.by = 1)

g2 <- g2 + geom_hline(yintercept = 0, color = "red")

# Unir gráficos

g <- ggarrange(g1, g2, labels = c("Modelo", "Residuos"),
               hjust = c(-2.5, -2.0))

print(g)

```
CONFIABILIDAD DE UN MODELO DE RLS

Es difícil comprobar las condiciones de los mínimos cuadrados. Hay que realizar esas verificaciones antes, puesto que si se está violando alguna condición o no se ajusta a los datos, no es posible confiar en las predicciones entregadas.

1) Bondad de ajuste: es el R cuadrado, sale en lm()

2) Distribución e independencia: cuando se cumplen las condiciones de los mínimos cuadrados, se observan ciertas características en el gráfico de los residuos:

- Se distribuyen aleatoriamente en torno a la línea de valor cero

- Forman una banda horizontal en torno a la línea de valor cero

- no hay residuos que se alejen del patrón que forman los demás

- no forman un patrón reconocible

Si se observan las características 1 y 4 es razonable suponer que las variables presentan una relación lineal.

el paquete car ofrece funciones para realizar el diagnóstico de modelos de regresión, entre ellos, está residualPlots(modelo, type = "pearson") que despliega gráficos de residuos.

También está marginalModelProts(modelo, sd = FALSE)

Evaluación del modelo

```{r}
library(car)
library(dplyr)
library(ggpubr)

# Cargar y filtrar los datos

datos <- mtcars |> filter(wt > 2 & wt < 5)

# Ajustar modelo con R

modelo <- lm(hp ~ disp, data = datos)

# Desplegar gráficos de residuos y mostrar pruebas de curvatura

cat("Pruebas de curvatura:\n")

residualPlots(modelo, type = "rstandard",
              id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
              col = "steelblue", pch = 20, col.quad = "red")

```

Verificar independencia de los residuos
```{r}
set.seed(19)
db <- durbinWatsonTest(modelo)
cat("\nPrueba de independencia:\n")
print(db)
```

Desplegar gráficos marginales
```{r}
marginalModelPlots(modelo, sd = TRUE,
                   id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
                   col = "steelblue", pch = 20, col.line = c("steelblue", "red"))
```

Prueba de la varianza del error no constante

```{r}
cat("\nPrueba de homocedasticidad:\n")
print(ncvTest(modelo))
```

Desplegar gráficos de influencia
```{r}
casos_influyentes <- influencePlot(modelo, id = list(cex = 0.7))
cat("\nCasos que podrían ser influyentes:\n")
print(casos_influyentes)
```


Calidad predictiva de un modelo de RLS.

Un modelo será generalizable si, para un conjunto de datos nuevo consigue predicciones con una calidad similar al que se consigue con los datos usados en su construcción.

Solo se puede estimar la capacidad de generalización de un modelo. La más frecuente es la validación cruzada, en donde tenemos los datos en dos grupos:

1) Conjunto de entrenamiento (contiene entre el 70% al 90% de las observaciones, se utiliza para ajustar la recta con el método de mínimos cuadrados)

2) Conjunto de prueba (contiene el 10% al 30% y evalúa el modelo con datos nuevos)

```{r}

datos <- mtcars |> filter(wt > 2 & wt < 5)

n <- nrow(datos)

# Obtener datos de prueba y entrenamiento

set.seed(101)
n_entrenamiento <- floor(0.8 * n)

i_entrenamiento <- sample.int(n = n, size = n_entrenamiento, replace = FALSE)

entrenamiento <- datos[i_entrenamiento , ]
prueba <- datos[-i_entrenamiento, ]

# Ajustar y mostrar el modelo con el conjunto de entrenamiento

modelo <- lm(hp ~ disp, data = entrenamiento)
print(summary(modelo))

```
Calcular el error cuadrado promedio para el conjunto de entrenamiento

```{r}
rmse_entrenamiento <- sqrt(mean(resid(modelo)**2))
cat("MSE para el conjunto de entrenamiento: ", rmse_entrenamiento, "\n")

# Hacer predicciones para el conjunto de prueba

predicciones <- predict(modelo, prueba)

# Calcular error cuadrado promedio para el conjunto de prueba.

error <- prueba[["hp"]] - predicciones

rmse_prueba <- sqrt(mean(error ** 2))
cat("MSE para el conjunto de prueba: ", rmse_prueba)

```

Validación cruzada en k pliegues: separar el conjunto de datos en k pliegues de igual tamaño, y, para cada una, hacer:

1) Tomar uno y reservarlo como conjunto de prueba

2) Ajustar la recta de mínimos cuadrados usando para ello los datos combinados de los k - 1 subconjuntos restantes

3) Estimar el error cuadrático medio usando para ello el conjunto de prueba

4) Estimar el error cuadrático medio del modelo, correspondiente a la media de los k MSE obtenidos en los pasos anteriores.

```{r}
library(caret)
library(dplyr)

datos <- mtcars |> filter(wt > 2 & wt < 5)

n <- nrow(datos)

# Obtener datos de prueba y entrenamiento de 5 pliegues

set.seed(111)

entrenamiento <- train(hp ~ disp, data = datos, method = "lm",
                       trControl = trainControl(method = "cv", number = 5))

modelo <- entrenamiento[["finalModel"]]
print(summary(modelo))

# Mostrar resultados de cada pliegue

cat("Errores en cada pliegue:\n")
print(entrenamiento[["resample"]])

# Mostrar el resultado estimado para el modelo

cat("\nError estimado para el modelo:\n")
print(entrenamiento[["results"]])
```

Pero, si la muestra es pequeña, una mejor alternativa es usar validación cruzada dejando uno fuera LOOCV

```{r}
library(caret)
library(dplyr)

datos <- mtcars |> filter(wt > 2 & wt < 5)

n <- nrow(datos)

# Obtener datos de prueba y entrenamiento de 5 pliegues

set.seed(111)

entrenamiento <- train(hp ~ disp, data = datos, method = "lm",
                       trControl = trainControl(method = "LOOCV"))

modelo <- entrenamiento[["finalModel"]]
print(summary(modelo))

# Mostrar errores de cada pliegue

cat("Predicciones en cada pliegue:\n")
print(entrenamiento[["pred"]])

# Mostrar el resultado estimado para el modelo

cat("\nError estimado para el modelo:\n")
print(entrenamiento[["results"]])
```










